{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: RenzeLou\n",
    "# use this script to preprocess all .tsv file to .json format and generate .source_vocab for each split(train/dev/test)\n",
    "# we don't do lowering because we use bert-base-cased\n",
    "\n",
    "import json,csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = []\n",
    "dev_file = []\n",
    "test_file = []\n",
    "labels = []\n",
    "desolate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_up(error_str:str)->list:\n",
    "    ans = []\n",
    "    lines=error_str.strip().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        res=line.split(\"\\t\")\n",
    "        ans += res\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_glue_error(data:list,stand:int):\n",
    "    ans = []\n",
    "    for element in data:\n",
    "        res=break_up(element)\n",
    "        ans += res\n",
    "    assert len(ans) % stand == 0\n",
    "    new_data = []\n",
    "    for i in range(len(ans)//stand):\n",
    "        new_element=ans[i*stand:(i+1)*stand]\n",
    "        new_data.append(new_element)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip first line\n",
      "104743\n"
     ]
    }
   ],
   "source": [
    "desolate = 0\n",
    "with open(\"./train.tsv\",\"r\",encoding=\"utf-8\") as train:\n",
    "    t=csv.reader(train,delimiter='\\t')\n",
    "    for i,line in enumerate(t):\n",
    "        if i==0:\n",
    "            print(\"skip first line\")\n",
    "            continue\n",
    "#         try:\n",
    "#             assert len(line) == 4\n",
    "#         except:\n",
    "# #             print(\"error_line:\",line)\n",
    "#             new_lines=fix_glue_error(line,4)\n",
    "#             for i,new_line in enumerate(new_lines):\n",
    "#                 print(\"line fixed:\",new_line)\n",
    "#                 lb=new_line[3]\n",
    "#                 if lb not in labels:\n",
    "#                     labels.append(lb)\n",
    "#                 label = labels.index(lb)   \n",
    "#                 instance = dict()\n",
    "#                 instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=new_line[0],new_line[1],new_line[2],label\n",
    "#                 train_file.append(instance)\n",
    "#             continue\n",
    "#         lb=line[3]\n",
    "#         if lb not in labels:\n",
    "#             labels.append(lb)\n",
    "#         label = labels.index(lb)\n",
    "#         instance = dict()\n",
    "#         instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=line[0],line[1],line[2],label\n",
    "#         train_file.append(instance)\n",
    "        new_lines=fix_glue_error(line,4)\n",
    "        for i,new_line in enumerate(new_lines):\n",
    "#             print(\"line fixed:\",new_line)\n",
    "            lb=new_line[3]\n",
    "            if lb not in labels:\n",
    "                labels.append(lb)\n",
    "            label = labels.index(lb)   \n",
    "            instance = dict()\n",
    "            instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=new_line[0],new_line[1],new_line[2],label\n",
    "            train_file.append(instance)\n",
    "    print(len(train_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip first line\n",
      "5463\n"
     ]
    }
   ],
   "source": [
    "with open(\"./dev.tsv\",\"r\",encoding=\"utf-8\") as dev:\n",
    "    t=csv.reader(dev,delimiter='\\t')\n",
    "    for i,line in enumerate(t):\n",
    "        if i==0:\n",
    "            print(\"skip first line\")\n",
    "            continue\n",
    "#         try:\n",
    "#             assert len(line) == 4\n",
    "#         except:\n",
    "# #             print(\"error_line:\",line)\n",
    "#             new_lines=fix_glue_error(line,4)\n",
    "#             for i,new_line in enumerate(new_lines):\n",
    "#                 print(\"line fixed:\",new_line)\n",
    "#                 lb=new_line[3]\n",
    "#                 if lb not in labels:\n",
    "#                     labels.append(lb)\n",
    "#                 label = labels.index(lb)   \n",
    "#                 instance = dict()\n",
    "#                 instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=new_line[0],new_line[1],new_line[2],label\n",
    "#                 dev_file.append(instance)\n",
    "#             continue\n",
    "#         lb=line[3]\n",
    "#         if lb not in labels:\n",
    "#             labels.append(lb)\n",
    "#         label = labels.index(lb)\n",
    "#         instance = dict()\n",
    "#         instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=line[0],line[1],line[2],label\n",
    "#         dev_file.append(instance)\n",
    "        new_lines=fix_glue_error(line,4)\n",
    "        for i,new_line in enumerate(new_lines):\n",
    "#             print(\"line fixed:\",new_line)\n",
    "            lb=new_line[3]\n",
    "            if lb not in labels:\n",
    "                labels.append(lb)\n",
    "            label = labels.index(lb)   \n",
    "            instance = dict()\n",
    "            instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=new_line[0],new_line[1],new_line[2],label\n",
    "            dev_file.append(instance)\n",
    "    print(len(dev_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idx from 862 to 870 has format error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip first line\n",
      "5463\n"
     ]
    }
   ],
   "source": [
    "with open(\"./test.tsv\",\"r\",encoding=\"utf-8\",errors=\"ignore\") as test:\n",
    "    t=csv.reader(test,delimiter='\\t')\n",
    "    for i,line in enumerate(t):\n",
    "        if i==0:\n",
    "            print(\"skip first line\")\n",
    "            continue\n",
    "#         try:\n",
    "#             assert len(line) == 3\n",
    "#         except:\n",
    "# #             print(\"error_line:\",line)\n",
    "#             new_lines=fix_glue_error(line,3)\n",
    "#             for i,new_line in enumerate(new_lines):\n",
    "#                 print(\"line fixed:\",new_line)\n",
    "#                 instance = dict()\n",
    "#                 instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=new_line[0],new_line[1],new_line[2],None\n",
    "#                 test_file.append(instance)\n",
    "#             continue\n",
    "#         instance = dict()\n",
    "#         instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=line[0],line[1],line[2],None\n",
    "#         test_file.append(instance)\n",
    "        new_lines=fix_glue_error(line,3)\n",
    "        for i,new_line in enumerate(new_lines):\n",
    "#             print(\"line fixed:\",new_line)\n",
    "            instance = dict()\n",
    "            instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=new_line[0],new_line[1],new_line[2],None\n",
    "            try:\n",
    "                t=int(new_line[0])\n",
    "            except:\n",
    "                print(\"error:\",new_line)\n",
    "            test_file.append(instance)\n",
    "    print(len(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not_entailment', 'entailment']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_filt(seq:str):\n",
    "    if seq is None:\n",
    "        return None\n",
    "    tokens = seq.split()\n",
    "    tokens = [t for t in tokens if t != \"\"]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_json(list_files:list,file_names:list,labels:list):\n",
    "    ''' write cached object to json file(train/dev/test)\n",
    "    and also generate data statistic information\n",
    "    \n",
    "    assert the order of input list is train/dev/test\n",
    "    '''\n",
    "    def seq_len(seq:str):\n",
    "        try:\n",
    "            return len(seq.split(\" \"))\n",
    "        except:\n",
    "            if seq is None:\n",
    "                return 0\n",
    "            else:\n",
    "                raise KeyError\n",
    "                \n",
    "    max_lens = []\n",
    "    for i,list_file in enumerate(list_files):\n",
    "        max_len = 0\n",
    "        new_list = []\n",
    "        for item in list_file:\n",
    "            item['seq1'],item['seq2'] = simple_filt(item[\"seq1\"]),simple_filt(item['seq2'])\n",
    "            max_len_two_seq=max(seq_len(item['seq1']),seq_len(item['seq2']))\n",
    "            max_len = max(max_len_two_seq,max_len)\n",
    "            new_list.append(item)\n",
    "        with open(file_names[i],\"w\") as f:\n",
    "            json.dump(new_list,f)\n",
    "        \n",
    "        print(\"successfully dump %s file\" %file_names[i])\n",
    "        max_lens.append(max_len)\n",
    "    \n",
    "    data_info = dict()\n",
    "    train_info = dict()\n",
    "    dev_info = dict()\n",
    "    test_info = dict()\n",
    "    idx2lb = dict()\n",
    "    for i,lb in enumerate(labels):\n",
    "        idx2lb[i] = lb\n",
    "    print(\"index to label:\",idx2lb)\n",
    "    \n",
    "    train_info[\"instance_num\"],train_info[\"instance_max_len\"] = len(list_files[0]),max_lens[0]\n",
    "    dev_info[\"instance_num\"],dev_info[\"instance_max_len\"] = len(list_files[1]),max_lens[1]\n",
    "    test_info[\"instance_num\"],test_info[\"instance_max_len\"] = len(list_files[2]),max_lens[2]\n",
    "    \n",
    "    \n",
    "    data_info[\"labels\"] = idx2lb\n",
    "    data_info[\"train\"] = train_info\n",
    "    data_info[\"dev\"] = dev_info\n",
    "    data_info[\"test\"] = test_info\n",
    "    \n",
    "    data_info_name = \"./data_info.json\"\n",
    "    with open(data_info_name,\"w\") as f:\n",
    "        json.dump(data_info,f)\n",
    "    print(\"successfully dump %s file\" %data_info_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not_entailment', 'entailment']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully dump train.json file\n",
      "successfully dump dev.json file\n",
      "successfully dump test.json file\n",
      "index to label: {0: 'not_entailment', 1: 'entailment'}\n",
      "successfully dump ./data_info.json file\n"
     ]
    }
   ],
   "source": [
    "write_to_json([train_file,dev_file,test_file],[\"train.json\",\"dev.json\",\"test.json\"],labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
