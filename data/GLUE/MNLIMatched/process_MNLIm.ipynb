{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: RenzeLou\n",
    "# use this script to preprocess all .tsv file to .json format and generate .source_vocab for each split(train/dev/test)\n",
    "# we don't do lowering because we use bert-base-cased\n",
    "\n",
    "import json,csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "csv.field_size_limit(500 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = []\n",
    "dev_file = []\n",
    "test_file = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'promptID', 'pairID', 'genre', 'sentence1_binary_parse', 'sentence2_binary_parse', 'sentence1_parse', 'sentence2_parse', 'sentence1', 'sentence2']\n",
      "['0', '31493', '31493', 'travel', '( ( ( ( ( ( ( ( Hierbas , ) ( ans seco ) ) , ) ( ans dulce ) ) , ) and ) frigola ) ( ( ( are just ) ( ( a ( few names ) ) ( worth ( ( keeping ( a look-out ) ) for ) ) ) ) . ) )', '( Hierbas ( ( is ( ( a name ) ( worth ( ( looking out ) for ) ) ) ) . ) )', '(ROOT (S (NP (NP (NNS Hierbas)) (, ,) (NP (NN ans) (NN seco)) (, ,) (NP (NN ans) (NN dulce)) (, ,) (CC and) (NP (NN frigola))) (VP (VBP are) (ADVP (RB just)) (NP (NP (DT a) (JJ few) (NNS names)) (PP (JJ worth) (S (VP (VBG keeping) (NP (DT a) (NN look-out)) (PP (IN for))))))) (. .)))', '(ROOT (S (NP (NNS Hierbas)) (VP (VBZ is) (NP (NP (DT a) (NN name)) (PP (JJ worth) (S (VP (VBG looking) (PRT (RP out)) (PP (IN for))))))) (. .)))', 'Hierbas, ans seco, ans dulce, and frigola are just a few names worth keeping a look-out for.', 'Hierbas is a name worth looking out for.']\n",
      "['1', '92164', '92164', 'government', '( ( ( The extent ) ( of ( the ( behavioral effects ) ) ) ) ( ( would ( ( depend ( in ( part ( on ( ( the structure ) ( of ( ( ( the ( individual ( account program ) ) ) and ) ( any limits ) ) ) ) ) ) ) ) ( on ( accessing ( the funds ) ) ) ) ) . ) )', '( ( Many people ) ( ( would ( be ( very ( unhappy ( to ( ( loose control ) ( over ( their ( own money ) ) ) ) ) ) ) ) ) . ) )', '(ROOT (S (NP (NP (DT The) (NN extent)) (PP (IN of) (NP (DT the) (JJ behavioral) (NNS effects)))) (VP (MD would) (VP (VB depend) (PP (IN in) (NP (NP (NN part)) (PP (IN on) (NP (NP (DT the) (NN structure)) (PP (IN of) (NP (NP (DT the) (JJ individual) (NN account) (NN program)) (CC and) (NP (DT any) (NNS limits)))))))) (PP (IN on) (S (VP (VBG accessing) (NP (DT the) (NNS funds))))))) (. .)))', '(ROOT (S (NP (JJ Many) (NNS people)) (VP (MD would) (VP (VB be) (ADJP (RB very) (JJ unhappy) (PP (TO to) (NP (NP (JJ loose) (NN control)) (PP (IN over) (NP (PRP$ their) (JJ own) (NN money)))))))) (. .)))', 'The extent of the behavioral effects would depend in part on the structure of the individual account program and any limits on accessing the funds.', 'Many people would be very unhappy to loose control over their own money.']\n"
     ]
    }
   ],
   "source": [
    "with open(\"./test_matched.tsv\",\"r\",encoding=\"utf-8\") as test:\n",
    "    t=csv.reader(test,delimiter='\\t')\n",
    "    for k,line in enumerate(t):\n",
    "        print(list(line))\n",
    "#         assert len(line) == 4\n",
    "        if k==2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'promptID', 'pairID', 'genre', 'sentence1_binary_parse', 'sentence2_binary_parse', 'sentence1_parse', 'sentence2_parse', 'sentence1', 'sentence2', 'label1', 'label2', 'label3', 'label4', 'label5', 'gold_label']\n",
      "['0', '63735', '63735n', 'slate', '( ( The ( new rights ) ) ( are ( nice enough ) ) )', '( Everyone ( really ( likes ( the ( newest benefits ) ) ) ) )', '(ROOT (S (NP (DT The) (JJ new) (NNS rights)) (VP (VBP are) (ADJP (JJ nice) (RB enough)))))', '(ROOT (S (NP (NN Everyone)) (VP (ADVP (RB really)) (VBZ likes) (NP (DT the) (JJS newest) (NNS benefits)))))', 'The new rights are nice enough', 'Everyone really likes the newest benefits ', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "['1', '91383', '91383c', 'government', '( ( This site ) ( ( includes ( ( ( ( a list ) ( of ( all ( award winners ) ) ) ) and ) ( ( a ( searchable database ) ) ( of ( Government ( Executive articles ) ) ) ) ) ) . ) )', '( ( ( The ( Government ( Executive articles ) ) ) ( housed ( on ( the website ) ) ) ) ( ( ( are not ) ( able ( to ( be searched ) ) ) ) . ) )', '(ROOT (S (NP (DT This) (NN site)) (VP (VBZ includes) (NP (NP (NP (DT a) (NN list)) (PP (IN of) (NP (DT all) (NN award) (NNS winners)))) (CC and) (NP (NP (DT a) (JJ searchable) (NN database)) (PP (IN of) (NP (NNP Government) (NNP Executive) (NNS articles)))))) (. .)))', '(ROOT (S (NP (NP (DT The) (NNP Government) (NNP Executive) (NNS articles)) (VP (VBN housed) (PP (IN on) (NP (DT the) (NN website))))) (VP (VBP are) (RB not) (ADJP (JJ able) (S (VP (TO to) (VP (VB be) (ADJP (JJ searched))))))) (. .)))', 'This site includes a list of all award winners and a searchable database of Government Executive articles.', 'The Government Executive articles housed on the website are not able to be searched.', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction']\n"
     ]
    }
   ],
   "source": [
    "with open(\"./dev_matched.tsv\",\"r\",encoding=\"utf-8\") as dev:\n",
    "    t=csv.reader(dev,delimiter='\\t')\n",
    "    for k,line in enumerate(t):\n",
    "        print(list(line))\n",
    "#         assert len(line) == 4\n",
    "        if k==2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'promptID', 'pairID', 'genre', 'sentence1_binary_parse', 'sentence2_binary_parse', 'sentence1_parse', 'sentence2_parse', 'sentence1', 'sentence2', 'label1', 'gold_label']\n",
      "['0', '31193', '31193n', 'government', '( ( Conceptually ( cream skimming ) ) ( ( has ( ( ( two ( basic dimensions ) ) - ) ( ( product and ) geography ) ) ) . ) )', '( ( ( Product and ) geography ) ( ( are ( what ( make ( cream ( skimming work ) ) ) ) ) . ) )', '(ROOT (S (NP (JJ Conceptually) (NN cream) (NN skimming)) (VP (VBZ has) (NP (NP (CD two) (JJ basic) (NNS dimensions)) (: -) (NP (NN product) (CC and) (NN geography)))) (. .)))', '(ROOT (S (NP (NN Product) (CC and) (NN geography)) (VP (VBP are) (SBAR (WHNP (WP what)) (S (VP (VBP make) (NP (NP (NN cream)) (VP (VBG skimming) (NP (NN work)))))))) (. .)))', 'Conceptually cream skimming has two basic dimensions - product and geography.', 'Product and geography are what make cream skimming work. ', 'neutral', 'neutral']\n",
      "['1', '101457', '101457e', 'telephone', '( you ( ( know ( during ( ( ( the season ) and ) ( i guess ) ) ) ) ( at ( at ( ( your level ) ( uh ( you ( ( ( lose them ) ( to ( the ( next level ) ) ) ) ( if ( ( if ( they ( decide ( to ( recall ( the ( the ( parent team ) ) ) ) ) ) ) ) ( ( the Braves ) ( decide ( to ( call ( to ( ( recall ( a guy ) ) ( from ( ( triple A ) ( ( ( then ( ( a ( double ( A guy ) ) ) ( ( goes up ) ( to ( replace him ) ) ) ) ) and ) ( ( a ( single ( A guy ) ) ) ( ( goes up ) ( to ( replace him ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )', '( You ( ( ( ( lose ( the things ) ) ( to ( the ( following level ) ) ) ) ( if ( ( the people ) recall ) ) ) . ) )', '(ROOT (S (NP (PRP you)) (VP (VBP know) (PP (IN during) (NP (NP (DT the) (NN season)) (CC and) (NP (FW i) (FW guess)))) (PP (IN at) (IN at) (NP (NP (PRP$ your) (NN level)) (SBAR (S (INTJ (UH uh)) (NP (PRP you)) (VP (VBP lose) (NP (PRP them)) (PP (TO to) (NP (DT the) (JJ next) (NN level))) (SBAR (IN if) (S (SBAR (IN if) (S (NP (PRP they)) (VP (VBP decide) (S (VP (TO to) (VP (VB recall) (NP (DT the) (DT the) (NN parent) (NN team)))))))) (NP (DT the) (NNPS Braves)) (VP (VBP decide) (S (VP (TO to) (VP (VB call) (S (VP (TO to) (VP (VB recall) (NP (DT a) (NN guy)) (PP (IN from) (NP (NP (RB triple) (DT A)) (SBAR (S (S (ADVP (RB then)) (NP (DT a) (JJ double) (NNP A) (NN guy)) (VP (VBZ goes) (PRT (RP up)) (S (VP (TO to) (VP (VB replace) (NP (PRP him))))))) (CC and) (S (NP (DT a) (JJ single) (NNP A) (NN guy)) (VP (VBZ goes) (PRT (RP up)) (S (VP (TO to) (VP (VB replace) (NP (PRP him))))))))))))))))))))))))))))', '(ROOT (S (NP (PRP You)) (VP (VBP lose) (NP (DT the) (NNS things)) (PP (TO to) (NP (DT the) (JJ following) (NN level))) (SBAR (IN if) (S (NP (DT the) (NNS people)) (VP (VBP recall))))) (. .)))', 'you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the Braves decide to call to recall a guy from triple A then a double A guy goes up to replace him and a single A guy goes up to replace him', 'You lose the things to the following level if the people recall.', 'entailment', 'entailment']\n"
     ]
    }
   ],
   "source": [
    "with open(\"./train.tsv\",\"r\",encoding=\"utf-8\") as train:\n",
    "    t=csv.reader(train,delimiter='\\t')\n",
    "    for k,line in enumerate(t):\n",
    "        print(list(line))\n",
    "#         assert len(line) == 4\n",
    "        if k==2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip first line\n"
     ]
    }
   ],
   "source": [
    "desolate = 0\n",
    "with open(\"./train.tsv\",\"r\",encoding=\"utf-8\") as train:\n",
    "    t=csv.reader(train,delimiter='\\t')\n",
    "    for i,line in enumerate(t):\n",
    "        if i==0:\n",
    "            print(\"skip first line\")\n",
    "            continue\n",
    "#         print(list(line))\n",
    "#         try:\n",
    "#             assert len(line) == 12\n",
    "#         except:\n",
    "#             print(\"error\")\n",
    "# #             print(line)\n",
    "#             desolate+=1\n",
    "#             continue\n",
    "        lb=line[-1]\n",
    "        if lb not in labels:\n",
    "            labels.append(lb)\n",
    "        label = labels.index(lb)\n",
    "        instance = dict()\n",
    "        instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=int(line[0]),line[8],line[9],label\n",
    "        train_file.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip first line\n"
     ]
    }
   ],
   "source": [
    "with open(\"./dev_matched.tsv\",\"r\",encoding=\"utf-8\") as dev:\n",
    "    t=csv.reader(dev,delimiter='\\t')\n",
    "    for i,line in enumerate(t):\n",
    "#         print(list(line))\n",
    "        if i==0:\n",
    "            print(\"skip first line\")\n",
    "            continue\n",
    "#         print(list(line))\n",
    "#         try:\n",
    "#             assert len(line) == 12\n",
    "#         except:\n",
    "#             print(\"error\")\n",
    "#             print(len(line))\n",
    "#             desolate+=1\n",
    "#             for p,c in enumerate(line):\n",
    "#                 print(\"index:\",p,\" context:\",c)\n",
    "#             continue\n",
    "        lb=line[-1]\n",
    "        if lb not in labels:\n",
    "            labels.append(lb)\n",
    "        label = labels.index(lb)\n",
    "        instance = dict()\n",
    "        instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=int(line[0]),line[8],line[9],label\n",
    "        dev_file.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip first line\n"
     ]
    }
   ],
   "source": [
    "with open(\"./test_matched.tsv\",\"r\",encoding=\"utf-8\") as test:\n",
    "    t=csv.reader(test,delimiter='\\t')\n",
    "    for i,line in enumerate(t):\n",
    "#         print(list(line))\n",
    "        if i==0:\n",
    "            print(\"skip first line\")\n",
    "            continue\n",
    "#         print(list(line))\n",
    "#         try:\n",
    "#             assert len(line) == 12\n",
    "#         except:\n",
    "#             print(\"error\")\n",
    "#             print(len(line))\n",
    "#             desolate+=1\n",
    "#             for p,c in enumerate(line):\n",
    "#                 print(\"index:\",p,\" context:\",c)\n",
    "#             continue\n",
    "#         lb=line[-1]\n",
    "#         if lb not in labels:\n",
    "#             labels.append(lb)\n",
    "#         label = labels.index(lb)\n",
    "        instance = dict()\n",
    "        instance[\"index\"],instance['seq1'],instance['seq2'],instance[\"label\"]=int(line[0]),line[8],line[9],None\n",
    "        test_file.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'seq1': 'The new rights are nice enough',\n",
       "  'seq2': 'Everyone really likes the newest benefits ',\n",
       "  'label': 0},\n",
       " {'index': 1,\n",
       "  'seq1': 'This site includes a list of all award winners and a searchable database of Government Executive articles.',\n",
       "  'seq2': 'The Government Executive articles housed on the website are not able to be searched.',\n",
       "  'label': 2},\n",
       " {'index': 2,\n",
       "  'seq1': \"uh i don't know i i have mixed emotions about him uh sometimes i like him but at the same times i love to see somebody beat him\",\n",
       "  'seq2': 'I like him for the most part, but would still enjoy seeing someone beat him.',\n",
       "  'label': 1},\n",
       " {'index': 3,\n",
       "  'seq1': \"yeah i i think my favorite restaurant is always been the one closest  you know the closest as long as it's it meets the minimum criteria you know of good food\",\n",
       "  'seq2': 'My favorite restaurants are always at least a hundred miles away from my house. ',\n",
       "  'label': 2},\n",
       " {'index': 4,\n",
       "  'seq1': \"i don't know um do you do a lot of camping\",\n",
       "  'seq2': 'I know exactly.',\n",
       "  'label': 2},\n",
       " {'index': 5,\n",
       "  'seq1': \"well that would be a help i wish they would do that here we have got so little landfill space left that we're going to run out before the end of this decade and it's really going to be\",\n",
       "  'seq2': 'We have plenty of space in the landfill.',\n",
       "  'label': 2},\n",
       " {'index': 6,\n",
       "  'seq1': 'yeah i know and i did that all through college and it worked too',\n",
       "  'seq2': 'I did that all through college but it never worked ',\n",
       "  'label': 2},\n",
       " {'index': 7,\n",
       "  'seq1': \"Calcutta seems to be the only other production center having any pretensions to artistic creativity at all, but ironically you're actually more likely to see the works of Satyajit Ray or Mrinal Sen shown in Europe or North America than in India itself.\",\n",
       "  'seq2': \"Most of Mrinal Sen's work can be found in European collections.\",\n",
       "  'label': 0},\n",
       " {'index': 8,\n",
       "  'seq1': 'If that investor were willing to pay extra for the security of limited downside, she could buy put options with a strike price of $98, which would lock in her profit on the shares at $18, less whatever the options cost.',\n",
       "  'seq2': 'THe strike price could be $8.',\n",
       "  'label': 2},\n",
       " {'index': 9,\n",
       "  'seq1': '3)  Dare you rise to the occasion, like Raskolnikov, and reject the petty rules that govern lesser men?',\n",
       "  'seq2': 'Would you rise up and defeaat all evil lords in the town?',\n",
       "  'label': 0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_file[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral', 'entailment', 'contradiction']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_filt(seq:str):\n",
    "    if seq is None:\n",
    "        return None\n",
    "    tokens = seq.split()\n",
    "    tokens = [t for t in tokens if t != \"\"]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_json(list_files:list,file_names:list,labels:list):\n",
    "    ''' write cached object to json file(train/dev/test)\n",
    "    and also generate data statistic information\n",
    "    \n",
    "    assert the order of input list is train/dev/test\n",
    "    '''\n",
    "    def seq_len(seq:str):\n",
    "        try:\n",
    "            return len(seq.split(\" \"))\n",
    "        except:\n",
    "            if seq is None:\n",
    "                return 0\n",
    "            else:\n",
    "                raise KeyError\n",
    "                \n",
    "    max_lens = []\n",
    "    for i,list_file in enumerate(list_files):\n",
    "        max_len = 0\n",
    "        new_list = []\n",
    "        for item in list_file:\n",
    "            item['seq1'],item['seq2'] = simple_filt(item[\"seq1\"]),simple_filt(item['seq2'])\n",
    "            max_len_two_seq=max(seq_len(item['seq1']),seq_len(item['seq2']))\n",
    "            max_len = max(max_len_two_seq,max_len)\n",
    "            new_list.append(item)\n",
    "        with open(file_names[i],\"w\") as f:\n",
    "            json.dump(new_list,f)\n",
    "        \n",
    "        print(\"successfully dump %s file\" %file_names[i])\n",
    "        max_lens.append(max_len)\n",
    "    \n",
    "    data_info = dict()\n",
    "    train_info = dict()\n",
    "    dev_info = dict()\n",
    "    test_info = dict()\n",
    "    idx2lb = dict()\n",
    "    for i,lb in enumerate(labels):\n",
    "        idx2lb[i] = lb\n",
    "    print(\"index to label:\",idx2lb)\n",
    "    \n",
    "    train_info[\"instance_num\"],train_info[\"instance_max_len\"] = len(list_files[0]),max_lens[0]\n",
    "    dev_info[\"instance_num\"],dev_info[\"instance_max_len\"] = len(list_files[1]),max_lens[1]\n",
    "    test_info[\"instance_num\"],test_info[\"instance_max_len\"] = len(list_files[2]),max_lens[2]\n",
    "    \n",
    "    \n",
    "    data_info[\"labels\"] = idx2lb\n",
    "    data_info[\"train\"] = train_info\n",
    "    data_info[\"dev\"] = dev_info\n",
    "    data_info[\"test\"] = test_info\n",
    "    \n",
    "    data_info_name = \"./data_info.json\"\n",
    "    with open(data_info_name,\"w\") as f:\n",
    "        json.dump(data_info,f)\n",
    "    print(\"successfully dump %s file\" %data_info_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully dump train.json file\n",
      "successfully dump dev.json file\n",
      "successfully dump test.json file\n",
      "index to label: {0: 'neutral', 1: 'entailment', 2: 'contradiction'}\n",
      "successfully dump ./data_info.json file\n"
     ]
    }
   ],
   "source": [
    "write_to_json([train_file,dev_file,test_file],[\"train.json\",\"dev.json\",\"test.json\"],labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
